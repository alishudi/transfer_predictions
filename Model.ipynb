{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WHOrfKB6bTsV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH3QBPg9TaAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0865f06-1569-47aa-966e-f0a4f85630f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0YjxLY2R-Lx"
      },
      "source": [
        "Путь к папке в которой лежат папки с данными и логи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-6sP6gWRtG6"
      },
      "source": [
        "path = '/content/drive/MyDrive/project/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy8ni-G5jAL4",
        "outputId": "d4aa7f4a-9a6e-45b9-ee8a-b52899da4b13"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "torch.manual_seed(1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f21697a3f70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfB8oL7bg3F5"
      },
      "source": [
        "Настроим логгинг"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4431NqOl3b-"
      },
      "source": [
        "import logging\n",
        "def start_log(path):\n",
        "    logging.basicConfig(\n",
        "        filename= path + 'models.log',\n",
        "        # filename='models.log',\n",
        "        filemode='a',\n",
        "        format='%(asctime)s - %(message)s', \n",
        "        datefmt='%d-%b-%y %H:%M:%S',\n",
        "        level = logging.INFO\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZcRlOyrvEAE"
      },
      "source": [
        "# Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuxURspodObh"
      },
      "source": [
        "Функция для загрузки датасета для данной позиции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QVGJJWqcgCR"
      },
      "source": [
        "def load_data(position, path, replaced):\n",
        "  data_type = 'data/'\n",
        "  if replaced:\n",
        "    data_type = 'data replaced/'\n",
        "  dpath = path + data_type + position\n",
        "  X_train = pd.read_csv(dpath + '_train.csv')\n",
        "  X_test = pd.read_csv(dpath + '_test.csv')\n",
        "  X_val = pd.read_csv(dpath + '_val.csv')\n",
        "  # logging.info(\"========================================================================\")\n",
        "  # logging.info(\"Loading dataset for {}\".format(position))\n",
        "  return X_train, X_test, X_val\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJLKFVh95PeR"
      },
      "source": [
        "Функция для загрузки датасета по всем позициям"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSrrb5g50v8B"
      },
      "source": [
        "def load_all(path, replaced):\n",
        "  X_train, X_test, X_val =  pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "  positions = ['Centerbacks', 'Forwards', 'Fullbacks', 'Midfielders', 'Wingers']\n",
        "  for position in positions:\n",
        "    df1, df2, df3 = load_data(position, path, replaced)\n",
        "    X_train = X_train.append(df1)\n",
        "    X_test = X_test.append(df2)\n",
        "    X_val = X_val.append(df3)\n",
        "  return X_train, X_test, X_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOaoNZqSjms5"
      },
      "source": [
        "Функция для корректировки показателей на владение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB1xTSjhdBen"
      },
      "source": [
        "def time_adj(df, attr_x, attr_y):\n",
        "  for attr in attr_x:\n",
        "    df[attr] = (df[attr] * 90) / df['minutes_x']\n",
        "  for attr in attr_y:\n",
        "    df[attr] = (df[attr] * 90) / df['minutes_y']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiM7CySwjyDf"
      },
      "source": [
        "Функция для обработки датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPGeVOLYj3uV"
      },
      "source": [
        "def preprocess(df, attr_list, to_90_attr, target, pca_attributes, encode_countries = True, do_PCA = True):\n",
        "    columns_x = attr_list\n",
        "    target_cols = []\n",
        "    target_cols.append(target)\n",
        "    if (encode_countries):\n",
        "        columns_x += ['country_x', 'country_y'] #у команд пока нет чемпионата, только у игроков, поэтому пока добавлю временно\n",
        "    attr_x = [name + \"_x\" for name in to_90_attr if (name in pl_attr)]\n",
        "    attr_y = [name + \"_y\" for name in to_90_attr if (name in target_cols)]\n",
        "    df = df[columns_x + target_cols + pca_attributes].dropna() #убираем лишние столбцы и наны\n",
        "    time_adj(df, attr_x, attr_y) #корректируем на 90 минут игрового времени\n",
        "    \n",
        "\n",
        "    if do_PCA:\n",
        "        pca = PCA(n_components=4)\n",
        "        x = df[pca_attributes].copy()\n",
        "        principalComponents = pca.fit_transform(x)\n",
        "        principalComponents = principalComponents / 100\n",
        "        principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])\n",
        "        df = pd.concat([df[columns_x + target_cols], principalDf], axis=1)\n",
        "    df = df.dropna() #PCA почему то одбавляет наны\n",
        "    df_y = df[target_cols]\n",
        "    df.drop(target_cols, inplace = True, axis = 1)\n",
        "    if (encode_countries):\n",
        "        df = pd.get_dummies(df, columns= ['country_x', 'country_y']) #энкодим чемпионат\n",
        "    return df, df_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf8MQZHrmp8_"
      },
      "source": [
        "Функция возвращающая готовые для обучения датафреймы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecGl0fD6oEB7"
      },
      "source": [
        "def create_dataframes(X_train, X_test, X_val, encode_countries, target, attributes, attr_to_90, pca_attributes, PCA = True):\n",
        "    X_train, y_train = preprocess(X_train, attributes, attr_to_90, target, pca_attributes, encode_countries, do_PCA = PCA)\n",
        "    X_test, y_test = preprocess(X_test, attributes, attr_to_90, target, pca_attributes, encode_countries, do_PCA = PCA)\n",
        "    X_val, y_val = preprocess(X_val, attributes, attr_to_90, target, pca_attributes, encode_countries, do_PCA = PCA)\n",
        "    logging.info(\"================================================================\")\n",
        "    logging.info(\"List of attributes: {}\".format(attributes))\n",
        "    logging.info(\"Target: {}\".format(target))\n",
        "    logging.info(\"Target mean values: train = {}, val = {}, test = {}\".format(y_train.mean(), y_val.mean(), y_test.mean()))\n",
        "    return (X_train, X_test, X_val, y_train, y_test, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnblEDfaxzGl"
      },
      "source": [
        "Итоговая функция для создания дафафреймов, вызывающая все вышеперечисленные функции в нужном порядке"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgtSMGHbxzXy"
      },
      "source": [
        "def dataframes(position, target, path, replaced = True, encode_countries = False, PCA = True):\n",
        "    # Загружаем датасет по нужным позициям\n",
        "    if position == 'All':\n",
        "        X_train, X_test, X_val = load_all(path, replaced)\n",
        "    else:\n",
        "        X_train, X_test, X_val = load_data(position, path, replaced)\n",
        "    \n",
        "    # Импортируем словарь с самыми важными показателями для предсказания каждого из важнейших атрибутов\n",
        "    with open(path + 'param.yaml') as f: attr_dict = yaml.load(f)\n",
        "    if target not in attr_dict:\n",
        "        raise ValueError('There is no attributes list in the dict for this target')\n",
        "    else:\n",
        "        attributes = attr_dict[target]\n",
        "\n",
        "    # Импортируем словарь с показателями для PCA\n",
        "    if PCA:\n",
        "        with open(path + 'PCA.yaml') as f: pca_dict = yaml.load(f)\n",
        "        pca_attributes = [attr for attr in pca_dict[position] if (attr not in attributes)]\n",
        "    else:\n",
        "        pca_attributes = []\n",
        "    \n",
        "    # Создаем все необходимые датафреймы и возвращаем их\n",
        "    return create_dataframes(X_train, X_test, X_val, encode_countries, target, attributes, [], pca_attributes, PCA = PCA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYOQOjLisEI9"
      },
      "source": [
        "# Модель 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8uTaV6pmwS0"
      },
      "source": [
        "Создадим даталоадер"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QObHs5VvsCEz"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, device='cuda'):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.len = len(y)\n",
        "        self.X   = X.values\n",
        "        self.y   = (y.values).reshape(-1, 1)\n",
        "        self.device = device\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        features = torch.FloatTensor(self.X[index]).to(device)\n",
        "        target = torch.FloatTensor(self.y[index]).to(device)\n",
        "\n",
        "        return features, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ha9KfJ1lFOG"
      },
      "source": [
        "Функция для создания даталоадеров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIunC1HAsIxe"
      },
      "source": [
        "def create_dataloaders(X_train, X_val, X_test, y_train, y_val, y_test):\n",
        "  Trainloader = DataLoader(Dataset(X_train, y_train), \n",
        "                        batch_size=1024, shuffle=True)\n",
        "  Validloader = DataLoader(Dataset(X_val, y_val),\n",
        "                        batch_size=1024, shuffle=False)\n",
        "  Testloader = DataLoader(Dataset(X_test, y_test),\n",
        "                        batch_size=1024, shuffle=False)\n",
        "  return (Trainloader, Validloader, Testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIjBNhUalUJY"
      },
      "source": [
        "Класс нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D2uZHzsTBVy"
      },
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, first_layer_size, second_layer_size):\n",
        "        super(NN, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(input_size, first_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(first_layer_size, second_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(second_layer_size, 1)\n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eb4I8TrTPxw"
      },
      "source": [
        "Функция для обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoToK7bcBnJo"
      },
      "source": [
        "def train(ep_count, epochs, Trainloader, Validloader, Testloader, optimizer, model, criterion):\n",
        "  train_losses, valid_losses = [], []\n",
        "  for i in range(epochs):\n",
        "    train_loss = 0\n",
        "    for X, y in Trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(X)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "      valid_loss = 0\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        for X, y in Validloader:\n",
        "          pred = model(X)\n",
        "          valid_loss += criterion(pred, y)\n",
        "        \n",
        "      if (i + 1) % 10 == 0:\n",
        "        train_losses.append(train_loss/len(Trainloader))\n",
        "        valid_losses.append(valid_loss/len(Validloader))\n",
        "        if (i + 1) % 20 == 0:\n",
        "          print(f\"Epoch: {i + 1 + ep_count} \", f\"Training Loss: {train_losses[-1]:.4f} \", f\"Valid Loss: {valid_losses[-1]:.4f}\")\n",
        "        if (i + 1) % 200 == 0:\n",
        "          logging.info(f\"Epoch: {i + 1 + ep_count} \" + f\"Training Loss: {train_losses[-1]:.4f} \" f\"Valid Loss: {valid_losses[-1]:.4f}\")\n",
        "      model.train()\n",
        "  \n",
        "  ep_count += epochs\n",
        "  test(model, Testloader, criterion) #тестируем \n",
        "  return ep_count, train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k471r99MIo4l"
      },
      "source": [
        "Функция для подсчета ошибки на тесте"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Jyf52WcD8K"
      },
      "source": [
        " def test(mod, Testloader, criterion): \n",
        "  test_loss = 0\n",
        "  mod.eval()\n",
        "  with torch.no_grad():\n",
        "    for X, y in Testloader:\n",
        "      pred = mod(X)\n",
        "      test_loss += criterion(pred, y)\n",
        "\n",
        "  mod.train()\n",
        "  print(\"Test loss {}\".format(test_loss))        \n",
        "  logging.info(\"Test loss {}\".format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA-2s3Yr2Zui"
      },
      "source": [
        "Функция для подсчета MAPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06dKso5Tx5ju"
      },
      "source": [
        "def MAPE(output, target):\n",
        "  return torch.mean(torch.minimum(torch.abs((target - output) / (target+ 0.000001)), torch.tensor(1.5)))   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-Jn7hu6zz5"
      },
      "source": [
        "График ошибки во время последнего обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klDCRbzeCFN"
      },
      "source": [
        "def make_plot():\n",
        "    plt.plot(train_losses, label='Training loss')\n",
        "    plt.plot(valid_losses, label='Validation loss')\n",
        "    plt.yscale(\"log\")\n",
        "    plt.legend(frameon=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEIKizZ6nrnE"
      },
      "source": [
        "Общая функция, принимает даталоадеры, возвращает модель обученную на них.\n",
        "Опционально принимает гиперпараметры, т.к. я пока не дописал автоподбор."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZn-5fufnuCA"
      },
      "source": [
        "def run(Trainloader, Validloader, Testloader, inp_layer, layer1, layer2, lr = 0.001, criterion = MAPE,\n",
        "        optimizer = optim.AdamW, scheduler = None, epochs = 200, plot = False):\n",
        "\n",
        "    # Инициализируем модель\n",
        "    model = NN(inp_layer, layer1, layer2).to('cuda')\n",
        "    optimizer = optimizer(model.parameters(), lr=lr)\n",
        "    ep_count = 0\n",
        "    scheduler_state = (scheduler.state_dict() if scheduler  else 'None')\n",
        "    logging.info(\"----------------------------------------------------------------------------------\")\n",
        "    logging.info('New model, model {}, criterion {}, optimizer {}'.format(model, criterion, optimizer))\n",
        "    logging.info('scheduler {}'.format(scheduler))\n",
        "    logging.info('{}'.format(scheduler_state))\n",
        "\n",
        "    # Обучаем модель\n",
        "    no_growth = 0\n",
        "    best_loss = 10000\n",
        "    best_model = copy.deepcopy(model)\n",
        "    while (no_growth < 2):\n",
        "        ep_count, train_losses, valid_losses = train(ep_count, epochs, Trainloader, Validloader, Testloader, optimizer, model, criterion)\n",
        "        if valid_losses[-1] < best_loss:\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_loss = valid_losses[-1]\n",
        "            no_growth = 0\n",
        "        else:\n",
        "            no_growth += 1\n",
        "        if ep_count > 2000 and valid_losses[-1] > 1:\n",
        "            return best_model, ep_count\n",
        "        if ep_count > 10000:\n",
        "            return best_model, ep_count\n",
        "    if plot:\n",
        "        make_plot()\n",
        "\n",
        "    return best_model, ep_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjH8PnKzvwhh"
      },
      "source": [
        "Финальная функция, принимает позицию и целевую переменную, возвращает предсказания_на_валидации, предсказания_на_тесте, мапе_на_валидации, мапе_на_тесте. Если модель выдает плохое качество пытается обучить её еще раз (потому что иногда модель застревает в \"плохом\" локальном минимуме)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdEz3xo3vfUX"
      },
      "source": [
        "def final(position, target, path, replaced = True, encode_countries = False, criterion = MAPE, PCA = True):\n",
        "    start_log(path)\n",
        "    X_train, X_test, X_val, y_train, y_test, y_val = dataframes(position, target, path, replaced = replaced, encode_countries = encode_countries, PCA = PCA)\n",
        "    Trainloader, Validloader, Testloader = create_dataloaders(X_train, X_val, X_test, y_train, y_val, y_test)\n",
        "\n",
        "    layer1, layer2 = 32, 16\n",
        "    lr = 0.001\n",
        "    i = 0\n",
        "\n",
        "    best_ev = 2\n",
        "    best_model = None\n",
        "    while True:\n",
        "        X, y = next(iter(Testloader))\n",
        "        model, ep_count = run(Trainloader, Validloader, Testloader, X_train.shape[1], layer1, layer2, lr = lr, criterion = criterion)\n",
        "        model.eval()\n",
        "        X, y = next(iter(Validloader))\n",
        "        err_val = criterion(model(X), y)\n",
        "        X, y = next(iter(Testloader))\n",
        "        err_test = criterion(model(X), y)\n",
        "\n",
        "        #обновляем наилучшую модель\n",
        "        if err_val.item() < best_ev:\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_ev = err_val.item()\n",
        "            X, y = next(iter(Testloader))\n",
        "            pred_test = best_model(X)\n",
        "            best_et = criterion(pred_test, y)\n",
        "            bl1 = layer1 #храним размеры слоев лучших моделей\n",
        "            bl2 = layer2\n",
        "\n",
        "        model.train()\n",
        "        if (best_ev < 0.1 * (2 + i)):\n",
        "            break\n",
        "        else:\n",
        "            i += 1\n",
        "            if i >= 2:\n",
        "                layer1 = X_train.shape[1]\n",
        "                layer2 = layer1 // 2\n",
        "            if ep_count >= 4000:\n",
        "                lr *= 2\n",
        "    \n",
        "    X, y = next(iter(Validloader))\n",
        "    pred_val = best_model(X)\n",
        "\n",
        "    return best_model, X_train.shape[1], bl1, bl2, pred_val, pred_test, best_ev, best_et.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfhpBqlP8lat"
      },
      "source": [
        "best_model, inp, bl1, bl2, pv, pt, ev, et = final('Wingers', 'crosses_y', '/content/drive/MyDrive/project/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plA6cnUiojcB"
      },
      "source": [
        "# Запуск и сохранение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QKr4jvaoqLy"
      },
      "source": [
        "Функция для сохранения модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiJsDnuo8tiO"
      },
      "source": [
        "def save_checkpoint(path, name, inp, bl1, bl2):\n",
        "    checkpoint = {'input_size': inp,\n",
        "                'layer1': bl1,\n",
        "                'layer2': bl2,\n",
        "                'state_dict': best_model.state_dict()}\n",
        "\n",
        "    torch.save(checkpoint, (path + 'models/' + name + 'checkpoint.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSvIK0NCpIrw"
      },
      "source": [
        "Функция для загрузки модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoPCK0YjlWZX"
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = NN(checkpoint['input_size'], checkpoint['layer1'], checkpoint['layer2'])\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAwNP9P1ne-5"
      },
      "source": [
        "# new_model = load_checkpoint((path + 'checkpoint.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko84ZH_ixe5x"
      },
      "source": [
        "Построим датафреймы с ошибками моделей для всех признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wZ2-aaSUaQM"
      },
      "source": [
        "pos_dict = {'Midfielders' :['sca_per90_y', 'gca_per90_y', 'npxg_xa_per90_y','passes_progressive_distance_y',\n",
        "'passes_into_penalty_area_y', 'passes_completed_y'],\n",
        "           'Forwards' : ['sca_per90_y', 'gca_per90_y', 'npxg_per90_y','shots_total_per90_y'],\n",
        "            'Wingers' : ['sca_per90_y', 'gca_per90_y', 'dribbles_completed_pct_y','crosses_y','carry_progressive_distance_y'],\n",
        "            'Centerbacks': ['aerials_won_y', 'tackles_won_y','interceptions_y'],\n",
        "            'Fullbacks' : ['tackles_won_y', 'crosses_y', 'interceptions_y']}\n",
        "pos = ['Centerbacks', 'Midfielders', 'Wingers', 'Forwards', 'Fullbacks']\n",
        "attrs = ['sca_per90_y', 'gca_per90_y', 'npxg_xa_per90_y', 'passes_progressive_distance_y', 'passes_into_penalty_area_y', 'passes_completed_y',\n",
        "         'npxg_per90_y', 'shots_total_per90_y',\n",
        "         'dribbles_completed_pct_y', 'crosses_y', 'carry_progressive_distance_y',\n",
        "         'aerials_won_y', 'tackles_won_y', 'interceptions_y']\n",
        "\n",
        "\n",
        "val_df = pd.DataFrame(columns = attrs, index = pos)\n",
        "test_df = pd.DataFrame(columns = attrs, index = pos)\n",
        "pos_frames = []\n",
        "for p, at_list in pos_dict.items():\n",
        "    pos_frame = pd.DataFrame(columns = at_list)\n",
        "    for at in at_list:\n",
        "        best_mod, inp, bl1, bl2, pv, pt, ev, et = final(p, at, '/content/drive/MyDrive/project/')\n",
        "        val_df.at[p, at] = ev\n",
        "        test_df.at[p, at] = et\n",
        "        name = p + '_' + at + '_'\n",
        "        save_checkpoint('/content/drive/MyDrive/project/', name, inp, bl1, bl2)\n",
        "        pos_frame[at] = np.reshape(pv.cpu().detach().numpy(), pv.cpu().detach().numpy().shape[0]).tolist()\n",
        "    pos_frames.append(pos_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "fxgPjGQPZ0C5",
        "outputId": "1fd1b38b-423d-477e-e7b3-d8a5cbd79383"
      },
      "source": [
        "val_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sca_per90_y</th>\n",
              "      <th>gca_per90_y</th>\n",
              "      <th>npxg_xa_per90_y</th>\n",
              "      <th>passes_progressive_distance_y</th>\n",
              "      <th>passes_into_penalty_area_y</th>\n",
              "      <th>passes_completed_y</th>\n",
              "      <th>npxg_per90_y</th>\n",
              "      <th>shots_total_per90_y</th>\n",
              "      <th>dribbles_completed_pct_y</th>\n",
              "      <th>crosses_y</th>\n",
              "      <th>carry_progressive_distance_y</th>\n",
              "      <th>aerials_won_y</th>\n",
              "      <th>tackles_won_y</th>\n",
              "      <th>interceptions_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Centerbacks</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.444826</td>\n",
              "      <td>0.426283</td>\n",
              "      <td>0.570315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Midfielders</th>\n",
              "      <td>0.365005</td>\n",
              "      <td>0.925911</td>\n",
              "      <td>0.513973</td>\n",
              "      <td>0.388074</td>\n",
              "      <td>0.476056</td>\n",
              "      <td>0.372991</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wingers</th>\n",
              "      <td>0.282728</td>\n",
              "      <td>0.49631</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.168855</td>\n",
              "      <td>0.596257</td>\n",
              "      <td>0.621595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Forwards</th>\n",
              "      <td>0.426603</td>\n",
              "      <td>0.689448</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.497541</td>\n",
              "      <td>0.296662</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fullbacks</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.476164</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.454195</td>\n",
              "      <td>0.53385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sca_per90_y gca_per90_y  ... tackles_won_y interceptions_y\n",
              "Centerbacks         NaN         NaN  ...      0.426283        0.570315\n",
              "Midfielders    0.365005    0.925911  ...           NaN             NaN\n",
              "Wingers        0.282728     0.49631  ...           NaN             NaN\n",
              "Forwards       0.426603    0.689448  ...           NaN             NaN\n",
              "Fullbacks           NaN         NaN  ...      0.454195         0.53385\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "BFaZdI-Bc5q0",
        "outputId": "85187607-ede8-411b-a3bd-edfdadf23420"
      },
      "source": [
        "test_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sca_per90_y</th>\n",
              "      <th>gca_per90_y</th>\n",
              "      <th>npxg_xa_per90_y</th>\n",
              "      <th>passes_progressive_distance_y</th>\n",
              "      <th>passes_into_penalty_area_y</th>\n",
              "      <th>passes_completed_y</th>\n",
              "      <th>npxg_per90_y</th>\n",
              "      <th>shots_total_per90_y</th>\n",
              "      <th>dribbles_completed_pct_y</th>\n",
              "      <th>crosses_y</th>\n",
              "      <th>carry_progressive_distance_y</th>\n",
              "      <th>aerials_won_y</th>\n",
              "      <th>tackles_won_y</th>\n",
              "      <th>interceptions_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Centerbacks</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.543358</td>\n",
              "      <td>0.519645</td>\n",
              "      <td>0.694901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Midfielders</th>\n",
              "      <td>0.401077</td>\n",
              "      <td>0.582115</td>\n",
              "      <td>0.562376</td>\n",
              "      <td>0.447747</td>\n",
              "      <td>0.65483</td>\n",
              "      <td>0.476808</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wingers</th>\n",
              "      <td>0.323212</td>\n",
              "      <td>0.588692</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.196729</td>\n",
              "      <td>0.61889</td>\n",
              "      <td>0.59857</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Forwards</th>\n",
              "      <td>0.262983</td>\n",
              "      <td>0.69492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.358908</td>\n",
              "      <td>0.317042</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fullbacks</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.640928</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.66632</td>\n",
              "      <td>0.651123</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sca_per90_y gca_per90_y  ... tackles_won_y interceptions_y\n",
              "Centerbacks         NaN         NaN  ...      0.519645        0.694901\n",
              "Midfielders    0.401077    0.582115  ...           NaN             NaN\n",
              "Wingers        0.323212    0.588692  ...           NaN             NaN\n",
              "Forwards       0.262983     0.69492  ...           NaN             NaN\n",
              "Fullbacks           NaN         NaN  ...       0.66632        0.651123\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUEF_Kz9zHoT"
      },
      "source": [
        "pos_frames[4].to_csv('/content/drive/MyDrive/project/pred_FB.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "useUMEr0Jaqy"
      },
      "source": [
        "val_df.to_csv('/content/drive/MyDrive/project/val_DF1.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c805A1dIJnaR"
      },
      "source": [
        "test_df.to_csv('/content/drive/MyDrive/project/test_DF1.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4NM7SQuvp2t"
      },
      "source": [
        "pos = ['All']\n",
        "attrs = [ 'sca_per90_y', 'gca_per90_y', 'npxg_xa_per90_y','passes_progressive_distance_y',\n",
        "'passes_into_penalty_area_y', 'passes_completed_y', 'npxg_per90_y','shots_total_per90_y', 'dribbles_completed_pct_y','crosses_y','carry_progressive_distance_y', \n",
        "'aerials_won_y', 'tackles_won_y','interceptions_y']\n",
        "\n",
        "\n",
        "val_df = pd.DataFrame(columns = attrs, index = pos)\n",
        "test_df = pd.DataFrame(columns = attrs, index = pos)\n",
        "\n",
        "for p in pos:\n",
        "    for at in attrs:\n",
        "        best_mod, inp, bl1, bl2, _, _, ev, et = final(p, at, '/content/drive/MyDrive/project/', PCA = False)\n",
        "        val_df.at[p, at] = ev\n",
        "        test_df.at[p, at] = et\n",
        "        name = p + '_' + at + '_'\n",
        "        save_checkpoint('/content/drive/MyDrive/project/', name, inp, bl1, bl2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHOrfKB6bTsV"
      },
      "source": [
        "# Логи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE2rf5xuSu_B"
      },
      "source": [
        "Просмотр логов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-AeaqWtQIq"
      },
      "source": [
        "!cat /content/drive/MyDrive/project/models.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TlZKEICca9B"
      },
      "source": [
        "y_train.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0FvcXStSrcJ"
      },
      "source": [
        "Очистка логов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzmht5Y3KHCQ"
      },
      "source": [
        "# !echo -n > /content/drive/MyDrive/project/models.log"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}